Project Overview
Reference architecture and description:


Building AI applications can be complex and time-consuming. By using LangChain.js and Azure Functions including Serverless technologies, you can greatly simplify the process. These tools streamline the development by managing infrastructure concerns and scaling automatically, allowing you to focus more on building the chatbot functionality and less on the underlying system architecture. This application is a chatbot that uses a set of enterprise documents to generate AI responses to user queries.

The code sample includes sample data to make trying the application quick and easy, but feel free to replace it with your own. You'll use a fictitious company called Contoso Real Estate, and the experience allows its customers to ask support questions about the usage of the company's products. The sample data includes a set of documents that describes the company's terms of service, privacy policy, and support guide.

## Understanding the project architecture

The architecture of the project is shown in the following diagram:

![AI Chat with RAG](../../docs/images/architecture.drawio.png)

To understand the architecture of the project, let's break it down into its individual components:

1. **Web App:**

   - The user interface for the chatbot is a web application built with **[Lit](https://lit.dev/)** (a library for building web components) and hosted using **[Azure Static Web Apps](https://learn.microsoft.com/azure/static-web-apps/overview)**. It provides a chat interface for users they can use to ask questions.
   - The code is in the `packages/webapp` folder.

2. **Serverless API:**

   - When a user sends a query through the web app, it is sent via HTTP to an API built using Azure Functions.
   - The API uses LangChain.js to process the query.
   - The API manages the logic of corporate documents and responds with answers to chat queries.
   - The code for this functionality will be shown later in the tutorial and is in the `packages/api` folder.

3. **Database:**

   - Text extracted from the documents and the vectors generated by LangChain.js is stored in Azure Cosmos DB for MongoDB vCore.
   - The database allows for the storage and retrieval of text chunks using vector search, which enables quick and relevant responses based on the user's queries.

4. **File Storage:**

   - The source documents such as terms of service, privacy policy, and support guides for the Contoso Real Estate are stored in Azure Blob Storage. This is where the PDF documents are uploaded and retrieved from.

5. **Azure OpenAI Service:**

   - This service is where the AI Model (a Large Language Model or LLM) is hosted. The model can understand and generate natural language. This is used to embed text chunks or generate answers based on the vector search from the database.

Let's examine the application flow based on the architecture diagram:

- A user interacts with the chat interface in the web app
- The web app sends the user's query to the Serverless API via HTTP calls
- The Serverless API interacts with Azure OpenAI Service to generate a response, using the data from Azure Cosmos DB for MongoDB vCore.
- If there's a need to reference the documents, Azure Blob Storage is used to retrieve the PDF documents.
- The generated response is then sent back to the web app and displayed to the user.

Project Structure

serverless-chat-langchainjs/
├── .github/
│   └── workflows/              # GitHub Actions workflows
├── data/                       # Sample documents for RAG
├── docs/                       # Documentation and tutorials
├── infra/                      # Infrastructure as Code (Bicep)
│   ├── app/                    # Application-specific infrastructure
│   └── core/                   # Core infrastructure components
├── packages/
│   ├── api/                    # Azure Functions backend
│   │   ├── src/
│   │   │   ├── functions/     # API endpoints
│   │   │   └── lib/          # Shared libraries
│   │   └── package.json
│   └── webapp/                # Frontend application
│       ├── src/
│       │   ├── components/    # Web components
│       │   └── services/     # API services
│       └── package.json
└── azure.yaml                 # Azure Developer CLI config

Step-by-Step Implementation Instructions
1. Initialize Project

# Create project directory
mkdir serverless-chat-langchainjs
cd serverless-chat-langchainjs

# Initialize Git repository
git init

# Create basic project structure
mkdir -p packages/{api,webapp} infra/{app,core} docs data

2. Setup Backend (Azure Functions)
1. Navigate to API directory:
cd packages/api

2. Initialize Node.js project:

npm init -y

3. Install required dependencies:

npm install @azure/functions @langchain/azure-openai langchain
npm install -D typescript @types/node

4. Create Azure Functions:
Create three functions as described in:

## Creating the other functions for the project

Let's create the other functions we will use throughout this project. We are going to create two more functions. They are:

- `documents-post`
- `documents-get`

5. Function Implementation Structure:

// packages/api/src/functions/chat-post/index.ts
import { app, HttpRequest, HttpResponseInit, InvocationContext } from "@azure/functions";
import { AzureOpenAI } from "@langchain/azure-openai";

export async function chatPost(request: HttpRequest, context: InvocationContext): Promise<HttpResponseInit> {
    // Implementation
}

app.http('chat-post', {
    methods: ['POST'],
    authLevel: 'anonymous',
    handler: chatPost
});

3. Setup Frontend (Static Web App)
1. Navigate to webapp directory:

cd packages/webapp

2. Initialize frontend project:+
npm init -y
npm install lit @microsoft/fast-foundation
npm install -D typescript vite @types/node

3. Create web component structure:
// packages/webapp/src/components/chat-window.ts
import { LitElement, html } from 'lit';

export class ChatWindow extends LitElement {
    static styles = css`/* styles */`;
    
    render() {
        return html`
            <div class="chat-container">
                <!-- Chat UI implementation -->
            </div>
        `;
    }
}

4. Infrastructure Setup (Bicep)

1. Create core infrastructure files:
- infra/main.bicep: Main infrastructure file
- infra/main.parameters.json: Parameters file
- infra/abbreviations.json: Resource naming conventions
2. Define Azure resources:
- Static Web App
- Function App
- Cosmos DB
- Azure OpenAI
- Storage Account

3. Configure Azure Developer CLI:
- Create azure.yaml with service definitions and hooks.

5. RAG Implementation
1. Create vector store service:

// packages/api/src/lib/vectorstore.ts
import { CosmosDatabaseCore } from "@langchain/community/vectorstores/cosmos";

export class VectorStore {
    private store: CosmosDatabaseCore;
    
    async initialize() {
        // Implementation
    }
    
    async addDocuments(documents: Document[]) {
        // Implementation
    }
    
    async similaritySearch(query: string) {
        // Implementation
    }
}

2. Implement document processing:
// packages/api/src/lib/document-processor.ts
import { PDFLoader } from "langchain/document_loaders/fs/pdf";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";

export class DocumentProcessor {
    async processDocument(file: Buffer) {
        // Implementation
    }
}

6. API Implementation
1. Chat endpoint (chat-post):
- Handle incoming chat requests
- Implement RAG logic
- Return formatted responses

2. Document endpoints:
- documents-post: Handle document uploads
- documents-get: Retrieve document information

7. Deployment Configuration
1. Create GitHub Actions workflow:
name: Azure Developer CLI
on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      # Implementation

2. Configure Azure Developer CLI:
name: serverless-chat-langchainjs
services:
  webapp:
    project: ./packages/webapp
    host: staticwebapp
  api:
    project: ./packages/api
    host: function

8.  Local Development Setup
1. Install development tools:
npm install -g azure-functions-core-tools@4
npm install -g @azure/static-web-apps-cli

2. Setup environment variables:
azd env set AZURE_LOCATION eastus2
azd env set AZURE_SUBSCRIPTION_ID <your-subscription-id>

3. Local development commands:
# Start API locally
cd packages/api
npm start

# Start webapp locally
cd packages/webapp
npm start

9. Deployment
1. Initial deployment:
azd auth login
azd up

2. Subsequent deployments:
azd deploy
or 
azd up --debug

3. Cleanup:
azd down --purge

10. Testing
1. Local testing:
# Test API endpoints
curl -X POST http://localhost:7071/api/chat-post -H "Content-Type: application/json" -d '{"message":"test"}'

# Test document upload
curl -X POST http://localhost:7071/api/documents-post -F "file=@./data/sample.pdf"

2. Production testing:
- Verify Static Web App deployment
- Test API endpoints
- Validate document processing
- Check vector search functionality

11. Monitoring and Logging
1. Configure Application Insights
2. Setup diagnostic settings
3. Implement error handling and logging